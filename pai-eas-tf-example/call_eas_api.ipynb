{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pai_tf_predict_proto import tf_predict_pb2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# List of CIFAR-10 classes\n",
    "classes = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'\n",
    "]\n",
    "\n",
    "# Helper function to find the index of the maximum value \n",
    "# in a Python list\n",
    "def argmax(mylist):\n",
    "    maxval = max(mylist)\n",
    "    for i in range(len(mylist)):\n",
    "        if mylist[i] == maxval:\n",
    "            return i\n",
    "\n",
    "# Helper function to unpickle CIFAR-10 data\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        unpacked = pickle.load(fo, encoding='bytes')\n",
    "    return unpacked\n",
    "\n",
    "# Helper function to convert image data into a usable format\n",
    "def reformatImage(images, index):\n",
    "    image = images[index].reshape(3, 32,32)\n",
    "    \n",
    "    # Transpose into [32, 32, 3] (put RGB channel data \"at the back\")\n",
    "    image = np.transpose(image, axes=[1,2,0])\n",
    "\n",
    "    return image\n",
    "\n",
    "# Read in test data and labels\n",
    "test_batch = unpickle('test_batch')\n",
    "\n",
    "# Pull out the 'data' and 'labels' sections\n",
    "data = test_batch[b'data']\n",
    "labels = test_batch[b'labels']\n",
    "\n",
    "# Call our PAI-EAS API on the first 25 test images\n",
    "for idx in range(0,25):\n",
    "\n",
    "    # Pull out a single image\n",
    "    img = reformatImage(data, idx)\n",
    "\n",
    "    # Normalize image into range [0, 1]\n",
    "    img = img / 255.0\n",
    "    \n",
    "    # Set up serializer, to get our image into an appropriate\n",
    "    # format to pass to the EAS API endpoint\n",
    "    request = tf_predict_pb2.PredictRequest()\n",
    "    \n",
    "    # \n",
    "    # NOTE, you need to replace 'serving_default', and conv2d_6_input' below with the appropriate field\n",
    "    # name returned by PAI EAS when you run:\n",
    "    #\n",
    "    # curl <path_to_api_endpoint> -H 'Authorization: <your_secret_token>' | jq\n",
    "    #\n",
    "    # Note that if you don't have 'jq' installed, you can leave off the '| jq', but the \n",
    "    # results will be a little harder to read since the JSON output won't be nicely formatted\n",
    "    #\n",
    "    # See this page for more details on what the output of 'curl' should look like:\n",
    "    # \n",
    "    #\n",
    "    request.signature_name = 'serving_default'\n",
    "    request.inputs['conv2d_6_input'].dtype = tf_predict_pb2.DT_FLOAT  # The type of the images parameter.\n",
    "    request.inputs['conv2d_6_input'].array_shape.dim.extend([1, 32, 32, 3])  # The shape of the images parameter.\n",
    "    request.inputs['conv2d_6_input'].float_val.extend(img.reshape(3072))  # The data about the images parameter.\n",
    "    \n",
    "    # Serialize data in the Protocol Buffers format to a string and transfer the string.\n",
    "    request_data = request.SerializeToString()\n",
    "\n",
    "    #\n",
    "    # Make the API call. Don't forget to replace 'your_eas_url_here' \n",
    "    # and 'your_eas_secret_token_here' with the values returned\n",
    "    # after your PAI-EAS instance is created\n",
    "    #\n",
    "    url = 'your_eas_url_here'\n",
    "    headers = {\"Authorization\": 'your_eas_secret_token_here'}\n",
    "    resp = requests.post(url, data=request_data, headers=headers)\n",
    "\n",
    "    # We still have to do a little manual work to \n",
    "    # determine the predicted label for our image, since\n",
    "    # the response is a 1x10 array of floating point values, \n",
    "    # and the \"predicted class\" is the index of the maximum\n",
    "    # floating point value in that array. Making things even\n",
    "    # trickier, the 1x10 array is encoded in a JSON-like structure\n",
    "    # where each entry is prefixed with \"float_val\", so we have to \n",
    "    # use a regular expression to collect those \"float_val\" fields\n",
    "    # into a list, then convert the resulting strings into \n",
    "    # floating point values, hence the complicated code below.\n",
    "    \n",
    "    # Convert response into usable data\n",
    "    response = tf_predict_pb2.PredictResponse()\n",
    "    response.ParseFromString(resp.content)\n",
    "    vals = str(response)\n",
    "    vals = re.findall('float_val: (.+)', vals)\n",
    "    vals = [float(x) for x in vals]\n",
    "    predicted_class = argmax(vals)\n",
    "    prediced_class = classes[predicted_class]\n",
    "    \n",
    "    # Print out actual and predicted classes\n",
    "    print(\"Predicted class: {}\".format(classes[predicted_class]))\n",
    "    print(\"Actual class: {}\".format(classes[labels[idx]]))\n",
    "    \n",
    "    # Display image\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(img)\n",
    "    plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
