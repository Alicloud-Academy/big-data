{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Code here inspired by this kernel on Kaggle: https://www.kaggle.com/veleon/spam-classification\n",
    "# \n",
    "# The code performs some pre-processing tasks on the \"ham\" and \"spam\" sample mail\n",
    "# provided by the above Kaggle project\n",
    "#\n",
    "# Namely: \n",
    "# - Strips email headers\n",
    "# - Extracts email content\n",
    "# - Trims word endings, normalizes capitalization, removes punctuation\n",
    "# - Discards non-text content (attachments, multimedia)\n",
    "import os\n",
    "import email\n",
    "import email.policy\n",
    "from bs4 import BeautifulSoup # Process HTML-formatted emails\n",
    "\n",
    "# Directory paths\n",
    "hamdir = './hamnspam/ham/'\n",
    "spamdir = './hamnspam/spam/'\n",
    "\n",
    "# Get a list of ham and spam filenames \n",
    "# Note: we assume all filenames are 37 characters long\n",
    "ham_filenames = [name for name in os.listdir(hamdir) if len(name) == 37]\n",
    "spam_filenames = [name for name in os.listdir(spamdir) if len(name) == 37]\n",
    "\n",
    "# Output some debugging info\n",
    "ham_count = len(ham_filenames)\n",
    "spam_count = len(spam_filenames)\n",
    "\n",
    "print('SPAM email count: {}'.format(spam_count))\n",
    "print('HAM email count: {}'.format(ham_count))\n",
    "print('HAM/SPAM Ratio: {ratio: 0.2f}% SPAM'.format(ratio=spam_count/ham_count * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in ham + spam email messages\n",
    "ham_emails = []\n",
    "for filename in ham_filenames:\n",
    "    f = open(hamdir + filename, 'rb')\n",
    "    try:\n",
    "        msg = email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "    except:\n",
    "        print('ERROR: Unable to read email {}'.format(hamdir + filename))\n",
    "        continue\n",
    "\n",
    "    ham_emails.append(msg)\n",
    "    \n",
    "spam_emails = []\n",
    "for filename in spam_filenames:\n",
    "    f = open(spamdir + filename, 'rb')\n",
    "    try:\n",
    "        msg = email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "    except:\n",
    "        print('ERROR: Unable to read email {}'.format(spamdir + filename))\n",
    "        continue\n",
    "\n",
    "    spam_emails.append(msg)\n",
    "        \n",
    "# Print out the first (non-multipart) ham + spam messages in each list, as a sanity check\n",
    "print('****** First HAM message ******\\n')\n",
    "for item in ham_emails:\n",
    "    if item.get_content_type() not in ['text/plain', 'text/html']:\n",
    "        continue\n",
    "    else:\n",
    "        print('*** HEADERS ***\\n')\n",
    "        print(item.values())\n",
    "        print('\\n*** BODY ***\\n')\n",
    "        print(item.get_content())\n",
    "        break\n",
    "print('\\n')\n",
    "\n",
    "print('*** First SPAM message ***\\n')\n",
    "for item in spam_emails:\n",
    "    if item.get_content_type() not in ['text/plain', 'text/html']:\n",
    "        continue\n",
    "    else:\n",
    "        print('*** HEADERS ***\\n')\n",
    "        print(item.values())\n",
    "        print('\\n*** BODY ***\\n')\n",
    "        print(item.get_content())\n",
    "        break\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In order to differentiate spam and ham, we need to develop features \n",
    "# which can be used to differentiate spam and ham emails. In our case, we'll\n",
    "# look at the text in the subject and body of the email. We extract text from our\n",
    "# emails below, ignoring everything except plaintext and HTML-formatted content\n",
    "# (meaning we ignore images, video, and other binary formats)\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# Convert email content to plaintext\n",
    "def html_to_text(html):\n",
    "    soup = bs(html, 'lxml')\n",
    "    try:\n",
    "        return soup.text\n",
    "    except:\n",
    "        print('ERROR: Unable to convert email\\'s HTML content to text')\n",
    "        return ''\n",
    "    \n",
    "def email_to_text(email):\n",
    "    plaintext = ''\n",
    "    \n",
    "    try:\n",
    "        plaintext += '\\n' + email['subject'] + '\\n'\n",
    "    except:\n",
    "        print('ERROR: Unable to parse email\\'s subject line')\n",
    "    \n",
    "    for part in email.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            try:\n",
    "                plaintext += '\\n' + part.get_content() + '\\n'\n",
    "            except:\n",
    "                print('ERROR: get_content() method failed on plaintext email, possibly an encoding issue')\n",
    "                continue\n",
    "        elif part.get_content_type() == 'text/html':\n",
    "            try:\n",
    "                html_content = part.get_content()\n",
    "            except:\n",
    "                print('ERROR: Unable to get content of HTML email message')\n",
    "                continue\n",
    "            \n",
    "            plaintext += '\\n' + html_to_text(html_content) + '\\n'\n",
    "    \n",
    "    return plaintext\n",
    "\n",
    "# Create text-only email corpus from ham and spam mail raw data\n",
    "ham_emails_textonly = [email_to_text(email) for email in ham_emails]\n",
    "spam_emails_textonly = [email_to_text(email) for email in spam_emails]\n",
    "\n",
    "# Sanity check: show first email in each list\n",
    "print('========= HAM =========')\n",
    "print(ham_emails_textonly[0])\n",
    "print('========= SPAM =========')\n",
    "print(spam_emails_textonly[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we have extracted the text, we need to score each word for \"spamminess\". \n",
    "#\n",
    "# One popular way to do this is by using Naive Bayes classification to judge emails\n",
    "# based on the \"spamminess\" of words used in the body. What we will do here is \n",
    "# to use ComplementNB (Complement Naive Bayes) from scikit-learn:\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/naive_bayes.html#complement-naive-bayes\n",
    "#\n",
    "# We're using ComplementNB because it is said to have better performance than ordinary Naive\n",
    "# bayes, especially for text classification tasks\n",
    "\n",
    "# Convert spam and non-spam email into feature vectors (using the CountVectorizer class)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(ham_emails_textonly + spam_emails_textonly)\n",
    "\n",
    "# Create label vector (0 = ham, 1 = spam)\n",
    "y = len(ham_emails_textonly) * [0] + len(spam_emails_textonly) * [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test and training sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12)\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "# Compute precisino and recall \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_predicted = cnb.predict(X_test)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_predicted)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a quick sanity check. Generate fake ham and spam emails, and see what predictions our model makes\n",
    "\n",
    "fake_ham = '''Hey Frank,\n",
    "\n",
    "I know it might not be the best time but I need to have a talk with you about the model we've been working on. It seems like Naive Bayes might not be the best fit for our use-case. Would you be willing to consider another model such as a linear classifier?\n",
    "'''.strip()\n",
    "\n",
    "fake_spam = '''\n",
    "Dear sir or madam,\n",
    "\n",
    "Congratulations! You have received an invite to be part of the money making scheme of the century! Earn $$$ from the comfort of your own home, selling replica luxury goods online. Simply make the calls! WE provide the customers and WE close the deal. All you have to do is call!\n",
    "\n",
    "Join today\n",
    "'''.strip()\n",
    "\n",
    "X_fakeham = vectorizer.transform([fake_ham])\n",
    "X_fakespam = vectorizer.transform([fake_spam])\n",
    "\n",
    "print('Fake HAM is classified as (0 for ham, 1 for spam): {}'.format(cnb.predict(X_fakeham)))\n",
    "print('Fake SPAM is classified as (0 for ham, 1 for spam): {}'.format(cnb.predict(X_fakespam)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
